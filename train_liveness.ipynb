{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model.livenessnet import LivenessNet\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "imagePaths = list(paths.list_images(\"/home/harsh/my_liveness_detector/archive/real_vs_fake/real-vs-fake/train/\"))\n",
    "                  \n",
    "print(\"[INFO] loading images...\")\n",
    "\n",
    "INIT_LR = 1e-4\n",
    "BS = 10\n",
    "EPOCHS = 50              \n",
    "                  \n",
    "data = []\n",
    "labels = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imagePath in imagePaths:\n",
    "    try:\n",
    "        # extract the class label from the filename, load the image and\n",
    "        # resize it to be a fixed 32x32 pixels, ignoring aspect ratio\n",
    "        label = imagePath.split(os.path.sep)[-2]\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.resize(image, (32, 32))\n",
    "\n",
    "        # update the data and labels lists, respectively\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "\n",
    "    except Exception as error:\n",
    "        print(\"Image {} error\".format(imagePath))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the data into a NumPy array, then preprocess it by scaling\n",
    "# all pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "# encode the labels (which are currently strings) as integers and then\n",
    "# one-hot encode them\n",
    "# print(labels)\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels = np_utils.to_categorical(labels, 2)\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(\n",
    "    data, labels, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\",\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network for 50 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "3598/3598 [==============================] - 414s 91ms/step - loss: 0.9039 - accuracy: 0.5155 - val_loss: 0.6722 - val_accuracy: 0.5885\n",
      "Epoch 2/50\n",
      "3598/3598 [==============================] - 286s 79ms/step - loss: 0.7270 - accuracy: 0.5538 - val_loss: 0.6506 - val_accuracy: 0.6239\n",
      "Epoch 3/50\n",
      "3598/3598 [==============================] - 289s 80ms/step - loss: 0.6846 - accuracy: 0.5804 - val_loss: 0.6235 - val_accuracy: 0.6662\n",
      "Epoch 4/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.6647 - accuracy: 0.6051 - val_loss: 0.6122 - val_accuracy: 0.6695\n",
      "Epoch 5/50\n",
      "3598/3598 [==============================] - 289s 80ms/step - loss: 0.6449 - accuracy: 0.6290 - val_loss: 0.6128 - val_accuracy: 0.6631\n",
      "Epoch 6/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.6386 - accuracy: 0.6362 - val_loss: 0.5933 - val_accuracy: 0.6935\n",
      "Epoch 7/50\n",
      "3598/3598 [==============================] - 290s 81ms/step - loss: 0.6273 - accuracy: 0.6521 - val_loss: 0.6026 - val_accuracy: 0.6743\n",
      "Epoch 8/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.6183 - accuracy: 0.6595 - val_loss: 0.6064 - val_accuracy: 0.6700\n",
      "Epoch 9/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.6119 - accuracy: 0.6674 - val_loss: 0.5825 - val_accuracy: 0.7093\n",
      "Epoch 10/50\n",
      "3598/3598 [==============================] - 296s 82ms/step - loss: 0.6073 - accuracy: 0.6710 - val_loss: 0.5821 - val_accuracy: 0.6922\n",
      "Epoch 11/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.6054 - accuracy: 0.6749 - val_loss: 0.5685 - val_accuracy: 0.7049\n",
      "Epoch 12/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.6002 - accuracy: 0.6803 - val_loss: 0.5671 - val_accuracy: 0.7094\n",
      "Epoch 13/50\n",
      "3598/3598 [==============================] - 290s 81ms/step - loss: 0.5959 - accuracy: 0.6860 - val_loss: 0.5898 - val_accuracy: 0.6787\n",
      "Epoch 14/50\n",
      "3598/3598 [==============================] - 290s 81ms/step - loss: 0.5967 - accuracy: 0.6861 - val_loss: 0.5622 - val_accuracy: 0.7153\n",
      "Epoch 15/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.5909 - accuracy: 0.6878 - val_loss: 0.6311 - val_accuracy: 0.6424\n",
      "Epoch 16/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5830 - accuracy: 0.6955 - val_loss: 0.5793 - val_accuracy: 0.6896\n",
      "Epoch 17/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.5839 - accuracy: 0.6953 - val_loss: 0.5442 - val_accuracy: 0.7295\n",
      "Epoch 18/50\n",
      "3598/3598 [==============================] - 294s 82ms/step - loss: 0.5802 - accuracy: 0.6995 - val_loss: 0.5734 - val_accuracy: 0.7019\n",
      "Epoch 19/50\n",
      "3598/3598 [==============================] - 296s 82ms/step - loss: 0.5729 - accuracy: 0.7061 - val_loss: 0.5815 - val_accuracy: 0.6850\n",
      "Epoch 20/50\n",
      "3598/3598 [==============================] - 297s 82ms/step - loss: 0.5757 - accuracy: 0.7029 - val_loss: 0.5713 - val_accuracy: 0.6950\n",
      "Epoch 21/50\n",
      "3598/3598 [==============================] - 318s 88ms/step - loss: 0.5757 - accuracy: 0.7018 - val_loss: 0.6024 - val_accuracy: 0.6678\n",
      "Epoch 22/50\n",
      "3598/3598 [==============================] - 296s 82ms/step - loss: 0.5685 - accuracy: 0.7049 - val_loss: 0.5582 - val_accuracy: 0.7105\n",
      "Epoch 23/50\n",
      "3598/3598 [==============================] - 296s 82ms/step - loss: 0.5721 - accuracy: 0.7047 - val_loss: 0.5895 - val_accuracy: 0.6812\n",
      "Epoch 24/50\n",
      "3598/3598 [==============================] - 296s 82ms/step - loss: 0.5704 - accuracy: 0.7060 - val_loss: 0.5420 - val_accuracy: 0.7258\n",
      "Epoch 25/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5632 - accuracy: 0.7171 - val_loss: 0.5766 - val_accuracy: 0.6878\n",
      "Epoch 26/50\n",
      "3598/3598 [==============================] - 290s 80ms/step - loss: 0.5622 - accuracy: 0.7205 - val_loss: 0.5864 - val_accuracy: 0.6814\n",
      "Epoch 27/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5635 - accuracy: 0.7108 - val_loss: 0.5911 - val_accuracy: 0.6782\n",
      "Epoch 28/50\n",
      "3598/3598 [==============================] - 298s 83ms/step - loss: 0.5635 - accuracy: 0.7098 - val_loss: 0.5827 - val_accuracy: 0.6858\n",
      "Epoch 29/50\n",
      "3598/3598 [==============================] - 297s 82ms/step - loss: 0.5563 - accuracy: 0.7205 - val_loss: 0.5679 - val_accuracy: 0.6999\n",
      "Epoch 30/50\n",
      "3598/3598 [==============================] - 295s 82ms/step - loss: 0.5557 - accuracy: 0.7204 - val_loss: 0.5803 - val_accuracy: 0.6863\n",
      "Epoch 31/50\n",
      "3598/3598 [==============================] - 289s 80ms/step - loss: 0.5559 - accuracy: 0.7186 - val_loss: 0.5856 - val_accuracy: 0.6865\n",
      "Epoch 32/50\n",
      "3598/3598 [==============================] - 290s 81ms/step - loss: 0.5538 - accuracy: 0.7221 - val_loss: 0.5910 - val_accuracy: 0.6811\n",
      "Epoch 33/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5510 - accuracy: 0.7207 - val_loss: 0.5417 - val_accuracy: 0.7208\n",
      "Epoch 34/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5522 - accuracy: 0.7187 - val_loss: 0.5517 - val_accuracy: 0.7109\n",
      "Epoch 35/50\n",
      "3598/3598 [==============================] - 291s 81ms/step - loss: 0.5415 - accuracy: 0.7353 - val_loss: 0.5831 - val_accuracy: 0.6855\n",
      "Epoch 36/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5442 - accuracy: 0.7279 - val_loss: 0.5529 - val_accuracy: 0.7119\n",
      "Epoch 37/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5412 - accuracy: 0.7319 - val_loss: 0.5522 - val_accuracy: 0.7149\n",
      "Epoch 38/50\n",
      "3598/3598 [==============================] - 311s 86ms/step - loss: 0.5454 - accuracy: 0.7303 - val_loss: 0.5536 - val_accuracy: 0.7143\n",
      "Epoch 39/50\n",
      "3598/3598 [==============================] - 297s 82ms/step - loss: 0.5427 - accuracy: 0.7272 - val_loss: 0.5792 - val_accuracy: 0.6928\n",
      "Epoch 40/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5333 - accuracy: 0.7360 - val_loss: 0.5795 - val_accuracy: 0.6846\n",
      "Epoch 41/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5361 - accuracy: 0.7368 - val_loss: 0.5356 - val_accuracy: 0.7236\n",
      "Epoch 42/50\n",
      "3598/3598 [==============================] - 292s 81ms/step - loss: 0.5371 - accuracy: 0.7331 - val_loss: 0.5427 - val_accuracy: 0.7145\n",
      "Epoch 43/50\n",
      "3598/3598 [==============================] - 293s 82ms/step - loss: 0.5347 - accuracy: 0.7353 - val_loss: 0.5462 - val_accuracy: 0.7135\n",
      "Epoch 44/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5353 - accuracy: 0.7327 - val_loss: 0.6285 - val_accuracy: 0.6679\n",
      "Epoch 45/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5360 - accuracy: 0.7331 - val_loss: 0.5438 - val_accuracy: 0.7164\n",
      "Epoch 46/50\n",
      "3598/3598 [==============================] - 294s 82ms/step - loss: 0.5293 - accuracy: 0.7381 - val_loss: 0.5154 - val_accuracy: 0.7386\n",
      "Epoch 47/50\n",
      "3598/3598 [==============================] - 294s 82ms/step - loss: 0.5298 - accuracy: 0.7402 - val_loss: 0.5748 - val_accuracy: 0.7029\n",
      "Epoch 48/50\n",
      "3598/3598 [==============================] - 293s 81ms/step - loss: 0.5279 - accuracy: 0.7379 - val_loss: 0.5233 - val_accuracy: 0.7372\n",
      "Epoch 49/50\n",
      "3598/3598 [==============================] - 295s 82ms/step - loss: 0.5306 - accuracy: 0.7396 - val_loss: 0.5664 - val_accuracy: 0.7058\n",
      "Epoch 50/50\n",
      "3598/3598 [==============================] - 294s 82ms/step - loss: 0.5295 - accuracy: 0.7409 - val_loss: 0.5383 - val_accuracy: 0.7246\n",
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        fake       0.65      0.91      0.76      5771\n",
      "        real       0.87      0.55      0.67      6223\n",
      "\n",
      "    accuracy                           0.72     11994\n",
      "   macro avg       0.76      0.73      0.72     11994\n",
      "weighted avg       0.77      0.72      0.72     11994\n",
      "\n",
      "[INFO] serializing network to '/home/harsh/my_liveness_detector/face_detector'...\n",
      "INFO:tensorflow:Assets written to: /home/harsh/my_liveness_detector/face_detector/assets\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model = LivenessNet.build(width=32, height=32, depth=3,\n",
    "                          classes=len(le.classes_))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "# train the network\n",
    "print(\"[INFO] training network for {} epochs...\".format(EPOCHS))\n",
    "H = model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=BS),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // BS,\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "# evaluate the network\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=BS)\n",
    "print(\n",
    "    classification_report(\n",
    "        testY.argmax(axis=1), predictions.argmax(axis=1), target_names=le.classes_\n",
    "    )\n",
    ")\n",
    "\n",
    "# save the network to disk\n",
    "print(\"[INFO] serializing network to '{}'...\".format('/home/harsh/my_liveness_detector/face_detector'))\n",
    "model.save('/home/harsh/my_liveness_detector/face_detector')\n",
    "\n",
    "# save the label encoder to disk\n",
    "f = open('/home/harsh/my_liveness_detector/le.pickle', \"wb\")\n",
    "f.write(pickle.dumps(le))\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        2320      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 148,562\n",
      "Trainable params: 148,242\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()\n",
    "plt.savefig('/home/harsh/my_liveness_detector/plot.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
